# W4M2
## 자율주행차 데이터라는 가정하에 2가지 아이디어
1. 씽크홀 카운트다운 정보 제공을 위한 도로 정보 수집.
2. 시간과 비용을 최적화한 여행 관광지 추천 알고리즘. 

# W4M3
## 어떤 내용이 가장 인상적이었나요?
### 각자 주목하는 부분이 달랐고 인상깊은 부분이 달랐음.

- 시간과 비용, 그리고 예의라는 3가지 제한사항(조건)을 걸고 프로젝트를 시작한 것이 인상깊었다. 이 3가지 조건이 기술적인 의사결정의 핵심 근거가 되었다고 생각한다.

- js를 동작하지 않고 html 파일만 크롤링 했는데도 10억개의 파일이 수집되었다는 것이 놀라웠음.

- 1초에 10000개씩 수집하기 위해서 페처와 파서의 성능을 최적화하는 과정이 인상깊었음.

- 또한, 1개의 거대한 인스턴스 대신 12개의 노드로 나누어서 시간 단축을 꽤한것도 인상깊은 내용이었음.

- 무분별한 크롤링이 서비스를 중단시킬수도, 저작권을 침해할수도 있다고 느낌.

- politeness라는 제한을 걸고, robots.txt를 지킨 것이 놀라웠음. 요즘에는 robots.txt를 지키지 않고 무분별하게 수집하는 사례가 많기 때문.

- 생각한 하드웨어 스펙의 상승 폭보다 크롤링 양이 극적으로 변한 느낌은 아니라고 생각함. 10년간 CPU, 네트워크, SSD 등의 성능 향상을 생각했을 때, 크롤링한 양이 동일한 시간 당 10배 이상 상승한 것이 아닌 이유가 뭐가 있을지 생각할 계기가 됨.

## 아키텍처에 대해 논의합니다.
### 글에서 소개된 아키텍쳐는 제한적인 상황을 극복하면서도 목표를 달성하기 위한 의사결정의 결과

- 파싱용 머신, 페치용 머신, 데이터 저장용 머신을 분리하지 않고, 12개의 독립 노드들이 모든 크롤러 기능을 포함하도록 했음.

    - 이유: 예산이 한정적

- 처음엔 단일 머신 성능의 극대화가 목표였다.

    - 과거에 큰 크롤링 시 하드웨어 병목 현상이 문제였기 때문 -> 하나의 aws i7i.4xlarge머신에 묶고 실행했으나 결과가 실망스러움 -> 시간이 부족해 이 방법 대신 수평 확장으로 전환

- 아키텍처 그림: 데이터가 저장된 redis를 중심으로 fetcher, pasher와 소통하며 동작

    - 한계점: 도메인 시드 목록(노드들이 처리할 도메인 url 목록)이 서로 공유되지 않아, 노드들은 자신에게 할당된 도메인 목록만 크롤링을 수행

## 어떤 의사결정이 놀라웠나요? 
- S3 대신 인스턴스 로컬 스토리지를 사용한 것: 비용 최적화를 위해 로컬 스토리지를 선택하였음.

- 처음엔 단일 머신 성능의 극대화가 목표였으나, 결과가 실망스러웠으며 시간이 부족해 수평 확장으로 목표를 전환 

    - 처음 목표 달성이 쉽지 않아 보일 때, 주어진 상황을 고려해 차선책을 마련해 실행하는 점이 인상적이었다.
